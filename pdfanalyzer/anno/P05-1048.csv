Title	Word Sense Disambiguation vs. Statistical Machine Translation	page=0 xpos=0 ypos=0 single-column centered left-indent right-indent font-largest page-top headchar-capital column-bottom above-double-space above-line-space
Author	Marine CARPUAT Dekai WU <sup>1</sup>	page=0 xpos=2 ypos=0 left-column left-indent right-over font-largest column-top line-double-space line-space headchar-capital column-bottom
E-mail	marine@cs.ust.hk dekai@cs.ust.hk	page=0 xpos=2 ypos=0 single-column left-indent right-indent font-smaller column-top symbol-atmark headchar-lower above-double-space above-line-space
B-Affiliation	Human Language Technology Center	page=0 xpos=3 ypos=0 single-column centered left-indent right-indent font-larger indented-line shorter-tail line-double-space line-space headchar-capital
I-Affiliation	HKUST	page=0 xpos=4 ypos=1 single-column centered left-indent right-indent font-larger indented-line shorter-tail headchar-capital
I-Affiliation	Department of Computer Science	page=0 xpos=3 ypos=1 single-column centered left-indent right-indent font-larger hanged-line longer-tail headchar-capital
I-Affiliation	University of Science and Technology	page=0 xpos=3 ypos=1 single-column centered left-indent right-indent font-larger hanged-line longer-tail headchar-capital
Address	Clear Water Bay, Hong Kong	page=0 xpos=3 ypos=1 single-column centered left-indent right-indent font-larger indented-line shorter-tail headchar-capital column-bottom above-blank-line above-double-space above-line-space
AbstractHeader	Abstract	page=0 xpos=1 ypos=2 left-column centered left-indent right-indent font-larger column-top line-blank-line line-double-space line-space string-abstract headchar-capital above-blank-line above-double-space above-line-space
B-Abstract	We directly investigate a subject of much	page=0 xpos=0 ypos=2 left-column centered left-indent right-indent hanged-line longer-tail line-blank-line line-double-space line-space headchar-capital
I-Abstract	recent debate: do word sense disambiga-	page=0 xpos=0 ypos=2 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	tion models help statistical machine trans-	page=0 xpos=0 ypos=3 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	lation quality? We present empirical re-	page=0 xpos=0 ypos=3 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	sults casting doubt on this common, but	page=0 xpos=0 ypos=3 left-column centered left-indent right-indent aligned-line headchar-lower
I-Abstract	unproved, assumption. Using a state-of-	page=0 xpos=0 ypos=3 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	the-art Chinese word sense disambigua-	page=0 xpos=0 ypos=3 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	tion model to choose translation candi-	page=0 xpos=0 ypos=4 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	dates for a typical IBM statistical MT	page=0 xpos=0 ypos=4 left-column centered left-indent right-indent aligned-line headchar-lower
I-Abstract	system, we find that word sense disam-	page=0 xpos=0 ypos=4 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	biguation does not yield significantly bet-	page=0 xpos=0 ypos=4 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	ter translation quality than the statistical	page=0 xpos=0 ypos=4 left-column centered left-indent right-indent aligned-line headchar-lower
I-Abstract	machine translation system alone. Error	page=0 xpos=0 ypos=5 left-column centered left-indent right-indent aligned-line headchar-lower
I-Abstract	analysis suggests several key factors be-	page=0 xpos=0 ypos=5 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	hind this surprising finding, including in-	page=0 xpos=0 ypos=5 left-column centered left-indent right-indent aligned-line headchar-lower tailchar-hiphen
I-Abstract	herent limitations of current statistical MT	page=0 xpos=0 ypos=5 left-column centered left-indent right-indent aligned-line headchar-lower
I-Abstract	architectures.	page=0 xpos=0 ypos=5 left-column left-indent right-indent aligned-line shorter-tail headchar-lower tailchar-period above-blank-line above-double-space above-line-space
B-SectionHeader	1 Introduction	page=0 xpos=0 ypos=6 left-column right-indent font-larger hanged-line line-blank-line line-double-space line-space numbered-heading1 above-double-space above-line-space
B-Body	Word sense disambiguation or WSD, the task of de-	page=0 xpos=0 ypos=6 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital tailchar-hiphen
I-Body	termining the correct sense of a word in context, is	page=0 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	a much studied problem area with a long and hon-	page=0 xpos=0 ypos=7 left-column full-justified aligned-line itemization headchar-lower tailchar-hiphen
I-Body	orable history. Recent years have seen steady ac-	page=0 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	curacy gains in WSD models, driven in particular	page=0 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	by controlled evaluations such as the Senseval series	page=0 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	of workshops. Word sense disambiguation is often	page=0 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	assumed to be an intermediate task, which should	page=0 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	then help higher level applications such as machine	page=0 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower above-double-space above-line-space
B-Footnote	<sup>1</sup> The authors would like to thank the Hong Kong Re-	page=0 xpos=0 ypos=8 left-column left-indent indented-line line-double-space line-space headchar-super tailchar-hiphen
I-Footnote	search Grants Council (RGC) for supporting this research	page=0 xpos=0 ypos=8 left-column full-justified font-smallest hanged-line headchar-lower
I-Footnote	in part through grants RGC6083/99E, RGC6256/00E, and	page=0 xpos=0 ypos=8 left-column full-justified font-smallest aligned-line headchar-lower
I-Footnote	DAG03/04.EG09, and several anonymous reviewers for in-	page=0 xpos=0 ypos=9 left-column full-justified font-smallest aligned-line headchar-capital tailchar-hiphen
I-Footnote	sights and suggestions.	page=0 xpos=0 ypos=9 left-column right-indent font-smallest aligned-line shorter-tail headchar-lower tailchar-period above-blank-line above-double-space above-line-space
Page	387	page=0 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
I-Body	translation or information retrieval. However, WSD	page=0 xpos=5 ypos=2 right-column full-justified column-top headchar-lower
I-Body	is usually performed and evaluated as a standalone	page=0 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower
I-Body	task, and to date there have been very few efforts to	page=0 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower
I-Body	integrate the learned WSD models into full statisti-	page=0 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	cal MT systems.	page=0 xpos=5 ypos=3 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	An energetically debated question at conferences	page=0 xpos=5 ypos=3 right-column left-indent indented-line longer-tail headchar-capital
I-Body	over the past year is whether even the new state-	page=0 xpos=5 ypos=3 right-column full-justified hanged-line headchar-lower tailchar-hiphen
I-Body	of-the-art word sense disambiguation models actu-	page=0 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ally have anything to offer to full statistical machine	page=0 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower
I-Body	translation systems. Among WSD circles, this can	page=0 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	sometimes elicit responses that border on implying	page=0 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	that even asking the question is heretical. In efforts	page=0 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	such as Senseval we tend to regard the construction	page=0 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	of WSD models as an obviously correct, if necessar-	page=0 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ily simplified, approach that will eventually lead to	page=0 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	essential disambiguation components within larger	page=0 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
E-Body	applications like machine translation.	page=0 xpos=5 ypos=5 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	There is no question that the word sense disam-	page=0 xpos=5 ypos=5 right-column left-indent indented-line longer-tail headchar-capital tailchar-hiphen
I-Body	biguation perspective has led to numerous insights in	page=0 xpos=5 ypos=5 right-column full-justified hanged-line headchar-lower
I-Body	machine translation, even of the statistical variety. It	page=0 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	is often simply an unstated assumption that any full	page=0 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	translation system, to achieve full performance, will	page=0 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	sooner or later have to incorporate individual WSD	page=0 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
E-Body	components.	page=0 xpos=5 ypos=6 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	However, in some translation architectures and	page=0 xpos=5 ypos=6 right-column left-indent indented-line longer-tail headchar-capital
I-Body	particularly in statistical machine translation (SMT),	page=0 xpos=5 ypos=7 right-column full-justified hanged-line headchar-lower tailchar-comma
I-Body	the translation engine already implicitly factors in	page=0 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
I-Body	many contextual features into lexical choice. From	page=0 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
I-Body	this standpoint, SMT models can be seen as WSD	page=0 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
I-Body	models in their own right, albeit with several major	page=0 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
E-Body	caveats.	page=0 xpos=5 ypos=8 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	But typical statistical machine translation models	page=0 xpos=5 ypos=8 right-column left-indent indented-line longer-tail headchar-capital
I-Body	only rely on a local context to choose among lexical	page=0 xpos=5 ypos=8 right-column full-justified hanged-line headchar-lower
I-Body	translation candidates, as discussed in greater detail	page=0 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	later. It is therefore often assumed that dedicated	page=0 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	WSD-based lexical choice models, which can incor-	page=0 xpos=5 ypos=9 right-column full-justified aligned-line headchar-capital tailchar-hiphen column-bottom above-blank-line above-double-space above-line-space
B-Footer	Proceedings of the 43rd Annual Meeting of the ACL, pages 387–394,	page=0 xpos=2 ypos=9 single-column left-indent right-indent font-smallest column-top line-blank-line line-double-space line-space headchar-capital tailchar-comma
I-Footer	Ann Arbor, June 2005.  2005 c Association for Computational Linguistics	page=0 xpos=1 ypos=9 single-column left-indent right-indent font-smallest hanged-line longer-tail year headchar-capital page-bottom
I-Body	porate a wider variety of context features, can make	page=1 xpos=0 ypos=0 left-column full-justified page-top headchar-lower
I-Body	better predictions than the “weaker” models implicit	page=1 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower
I-Body	in statistical MT, and that these predictions will help	page=1 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower
E-Body	the translation quality.	page=1 xpos=0 ypos=0 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	Nevertheless, this assumption has not been em-	page=1 xpos=0 ypos=0 left-column left-indent indented-line longer-tail line-space headchar-capital tailchar-hiphen
I-Body	pirically verified, and we should not simply assume	page=1 xpos=0 ypos=1 left-column full-justified hanged-line headchar-lower
I-Body	that WSD models can contribute more than what the	page=1 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower
I-Body	SMT models perform. It may behoove us to take	page=1 xpos=0 ypos=1 left-column full-justified aligned-line headchar-capital
I-Body	note of the sobering fact that, perhaps analogously,	page=1 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	WSD has yet to be conclusively shown to help in-	page=1 xpos=0 ypos=1 left-column full-justified aligned-line headchar-capital tailchar-hiphen
I-Body	formation retrieval systems after many years of at-	page=1 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	tempts.	page=1 xpos=0 ypos=2 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	In this work, we propose to directly investigate	page=1 xpos=0 ypos=2 left-column left-indent indented-line longer-tail line-space headchar-capital
I-Body	whether word sense disambiguation—at least as it is	page=1 xpos=0 ypos=2 left-column full-justified hanged-line headchar-lower
I-Body	typically currently formulated—is useful for statis-	page=1 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tical machine translation. We tackle a real Chinese	page=1 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	to English translation task using a state-of-the-art su-	page=1 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	pervised WSD system and a typical SMT model. We	page=1 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	show that the unsupervised SMT model, trained on	page=1 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	parallel data without any manual sense annotation,	page=1 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	yields higher BLEU scores than the case where the	page=1 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	SMT model makes use of the lexical choice predic-	page=1 xpos=0 ypos=4 left-column full-justified aligned-line headchar-capital tailchar-hiphen
I-Body	tions from the supervised WSD model, which are	page=1 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	more expensive to create. The reasons for the sur-	page=1 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	prising difficulty of improving over the translation	page=1 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	quality of the SMT model are then discussed and	page=1 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
E-Body	analyzed.	page=1 xpos=0 ypos=5 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-double-space above-line-space
B-SectionHeader	2 Word sense disambiguation vs.	page=1 xpos=0 ypos=5 left-column right-indent font-larger aligned-line longer-tail line-double-space line-space numbered-heading1 tailchar-period
I-SectionHeader	statistical machine translation	page=1 xpos=0 ypos=5 left-column left-indent right-indent font-larger indented-line shorter-tail headchar-lower above-double-space above-line-space
B-Body	We begin by examining the respective strengths and	page=1 xpos=0 ypos=6 left-column full-justified hanged-line longer-tail line-double-space line-space headchar-capital
I-Body	weaknesses of dedicated WSD models versus full	page=1 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	SMT models, that could be expected to be relevant	page=1 xpos=0 ypos=6 left-column full-justified aligned-line headchar-capital
E-Body	to improving lexical choice.	page=1 xpos=0 ypos=6 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-double-space above-line-space
B-SubsectionHeader	2.1 Features Unique to WSD	page=1 xpos=0 ypos=7 left-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	Dedicated WSD is typically cast as a classification	page=1 xpos=0 ypos=7 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	task with a predefined sense inventory. Sense dis-	page=1 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tinctions and granularity are often manually prede-	page=1 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	fined, which means that they can be adapted to the	page=1 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	task at hand, but also that the translation candidates	page=1 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
E-Body	are limited to an existing set.	page=1 xpos=0 ypos=8 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	To improve accuracy, dedicated WSD models typ-	page=1 xpos=0 ypos=8 left-column left-indent indented-line longer-tail line-space headchar-capital tailchar-hiphen
I-Body	ically employ features that are not limited to the lo-	page=1 xpos=0 ypos=8 left-column full-justified hanged-line headchar-lower tailchar-hiphen
I-Body	cal context, and that include more linguistic infor-	page=1 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	mation than the surface form of words. This of-	page=1 xpos=0 ypos=9 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ten requires several stages of preprocessing, such	page=1 xpos=0 ypos=9 left-column full-justified aligned-line headchar-lower above-blank-line above-double-space above-line-space
Page	388	page=1 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
I-Body	as part-of-speech tagging and/or parsing. (Prepro-	page=1 xpos=5 ypos=0 right-column full-justified column-top headchar-lower tailchar-hiphen
I-Body	cessor domain can be an issue, since WSD accu-	page=1 xpos=5 ypos=0 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	racy may suffer from domain mismatches between	page=1 xpos=5 ypos=0 right-column full-justified aligned-line headchar-lower
I-Body	the data the preprocessors were trained on, and the	page=1 xpos=5 ypos=0 right-column full-justified aligned-line headchar-lower
I-Body	data they are applied to.) For example, a typi-	page=1 xpos=5 ypos=0 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	cal dedicated WSD model might employ features	page=1 xpos=5 ypos=0 right-column full-justified aligned-line headchar-lower
I-Body	as described by Yarowsky and Florian (2002) in	page=1 xpos=5 ypos=1 right-column full-justified aligned-line year headchar-lower
I-Body	their “feature-enhanced naive Bayes model”, with	page=1 xpos=5 ypos=1 right-column full-justified aligned-line headchar-lower
I-Body	position-sensitive, syntactic, and local collocational	page=1 xpos=5 ypos=1 right-column full-justified aligned-line headchar-lower
I-Body	features. The feature set made available to the WSD	page=1 xpos=5 ypos=1 right-column full-justified aligned-line headchar-lower
I-Body	model to predict lexical choices is therefore much	page=1 xpos=5 ypos=1 right-column full-justified aligned-line headchar-lower
E-Body	richer than that used by a statistical MT model.	page=1 xpos=5 ypos=2 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	Also, dedicated WSD models can be supervised,	page=1 xpos=5 ypos=2 right-column left-indent indented-line longer-tail line-space headchar-capital tailchar-comma
I-Body	which yields significantly higher accuracies than un-	page=1 xpos=5 ypos=2 right-column full-justified hanged-line headchar-lower tailchar-hiphen
I-Body	supervised. For the experiments described in this	page=1 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower
I-Body	study we employed supervised training, exploit-	page=1 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ing the annotated corpus that was produced for the	page=1 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower
E-Body	Senseval-3 evaluation.	page=1 xpos=5 ypos=3 right-column right-indent aligned-line shorter-tail headchar-capital tailchar-period above-blank-line above-double-space above-line-space
B-SubsectionHeader	2.2 Features Unique to SMT	page=1 xpos=5 ypos=3 right-column right-indent aligned-line longer-tail line-blank-line line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	Unlike lexical sample WSD models, SMT models	page=1 xpos=5 ypos=4 right-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	simultaneously translate complete sentences rather	page=1 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	than isolated target words. The lexical choices are	page=1 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	made in a way that heavily prefers phrasal cohesion	page=1 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	in the output target sentence, as scored by the lan-	page=1 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	guage model. That is, the predictions benefit from	page=1 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	the sentential context of the target language. This	page=1 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	has the general effect of improving translation flu-	page=1 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	ency.	page=1 xpos=5 ypos=5 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	The WSD accuracy of the SMT model depends	page=1 xpos=5 ypos=6 right-column left-indent indented-line longer-tail line-space headchar-capital
I-Body	critically on the phrasal cohesion of the target lan-	page=1 xpos=5 ypos=6 right-column full-justified hanged-line headchar-lower tailchar-hiphen
I-Body	guage. As we shall see, this phrasal cohesion prop-	page=1 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	erty has strong implications for the utility of WSD.	page=1 xpos=5 ypos=6 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	In other work (forthcoming), we investigated	page=1 xpos=5 ypos=6 right-column left-indent indented-line longer-tail line-space headchar-capital
I-Body	the inverse question of evaluating the Chinese-to-	page=1 xpos=5 ypos=7 right-column full-justified hanged-line headchar-lower tailchar-hiphen
I-Body	English SMT model on word sense disambigua-	page=1 xpos=5 ypos=7 right-column full-justified aligned-line headchar-capital tailchar-hiphen
I-Body	tion performance, using standard WSD evaluation	page=1 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
I-Body	methodology and datasets from the Senseval-3 Chi-	page=1 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	nese lexical sample task. We showed the accuracy of	page=1 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
I-Body	the SMT model to be significantly lower than that of	page=1 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	all the dedicated WSD models considered, even af-	page=1 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ter adding the lexical sample data to the training set	page=1 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	for SMT to allow for a fair comparison. These re-	page=1 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	sults highlight the relative strength, and the potential	page=1 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	hoped-for advantage of dedicated supervised WSD	page=1 xpos=5 ypos=9 right-column full-justified aligned-line headchar-lower
E-Body	models.	page=1 xpos=5 ypos=9 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period page-bottom
B-SectionHeader	3 The WSD system	page=2 xpos=0 ypos=0 left-column right-indent font-larger page-top numbered-heading1 above-double-space above-line-space
B-Body	The WSD system used for the experiments is based	page=2 xpos=0 ypos=0 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	on the model that achieved the best performance, by	page=2 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower
I-Body	a large margin, on the Senseval-3 Chinese lexical	page=2 xpos=0 ypos=0 left-column full-justified aligned-line itemization headchar-lower
E-Body	sample task (Carpuat et al., 2004).	page=2 xpos=0 ypos=0 left-column right-indent aligned-line shorter-tail year headchar-lower tailchar-period above-double-space above-line-space
B-SubsectionHeader	3.1 Classification model	page=2 xpos=0 ypos=1 left-column right-indent aligned-line shorter-tail line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	The model consists of an ensemble of four voting	page=2 xpos=0 ypos=1 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
E-Body	models combined by majority vote.	page=2 xpos=0 ypos=1 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	The first voting model is a naive Bayes model,	page=2 xpos=0 ypos=1 left-column left-indent indented-line longer-tail headchar-capital tailchar-comma
I-Body	since Yarowsky and Florian (2002) found this model	page=2 xpos=0 ypos=2 left-column full-justified hanged-line year headchar-lower
I-Body	to be the most accurate classifier in a comparative	page=2 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	study on a subset of Senseval-2 English lexical sam-	page=2 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	ple data.	page=2 xpos=0 ypos=2 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	The second voting model is a maximum entropy	page=2 xpos=0 ypos=2 left-column left-indent indented-line longer-tail headchar-capital
I-Body	model (Jaynes, 1978), since Klein and Manning	page=2 xpos=0 ypos=3 left-column full-justified hanged-line year headchar-lower
I-Body	(2002) found that this model yielded higher accu-	page=2 xpos=0 ypos=3 left-column full-justified aligned-line year tailchar-hiphen
I-Body	racy than naive Bayes in a subsequent comparison	page=2 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	of WSD performance. (Note, however, that a differ-	page=2 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ent subset of either Senseval-1 or Senseval-2 English	page=2 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
E-Body	lexical sample data was used for their comparison.)	page=2 xpos=0 ypos=4 left-column right-indent aligned-line headchar-lower
B-Body	The third voting model is a boosting model (Fre-	page=2 xpos=0 ypos=4 left-column left-indent indented-line headchar-capital tailchar-hiphen
I-Body	und and Schapire, 1997), since has consistently	page=2 xpos=0 ypos=4 left-column full-justified hanged-line year headchar-lower
I-Body	turned in very competitive scores on related tasks	page=2 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	such as named entity classification (Carreras et al.,	page=2 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	2002) . Specifically, an AdaBoost.MH model was	page=2 xpos=0 ypos=5 left-column full-justified aligned-line year
I-Body	used (Schapire and Singer, 2000), which is a multi-	page=2 xpos=0 ypos=5 left-column full-justified aligned-line year headchar-lower tailchar-hiphen
I-Body	class generalization of the original boosting algo-	page=2 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	rithm, with boosting on top of decision stump clas-	page=2 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	sifiers (i.e., decision trees of depth one).	page=2 xpos=0 ypos=5 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	The fourth voting model is a Kernel PCA-based	page=2 xpos=0 ypos=6 left-column left-indent indented-line longer-tail headchar-capital
I-Body	model (Wu et al., 2004). Kernel Principal Compo-	page=2 xpos=0 ypos=6 left-column full-justified hanged-line year headchar-lower tailchar-hiphen
I-Body	nent Analysis (KPCA) is a nonlinear kernel method	page=2 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	for extracting nonlinear principal components from	page=2 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	vector sets where, conceptually, the n-dimensional	page=2 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	input vectors are nonlinearly mapped from their	page=2 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	original space R <sup>n</sup> to a high-dimensional feature	page=2 xpos=0 ypos=7 left-column full-justified font-largest aligned-line headchar-lower
I-Body	space F where linear PCA is performed, yielding a	page=2 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	transform by which the input vectors can be mapped	page=2 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	nonlinearly to a new set of vectors (Schölkopf et al.,	page=2 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	1998). WSD can be performed by a Nearest Neigh-	page=2 xpos=0 ypos=8 left-column full-justified aligned-line year tailchar-hiphen
I-Body	bor Classifier in the high-dimensional KPCA feature	page=2 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	space. (Carpuat et al., 2004) showed that KPCA-	page=2 xpos=0 ypos=8 left-column full-justified aligned-line year headchar-lower tailchar-hiphen
I-Body	based WSD models achieve close accuracies to the	page=2 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	best individual WSD models, while having a signif-	page=2 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	icantly different bias.	page=2 xpos=0 ypos=9 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	All these classifiers have the ability to handle	page=2 xpos=0 ypos=9 left-column left-indent indented-line longer-tail headchar-capital above-blank-line above-double-space above-line-space
Page	389	page=2 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
I-Body	large numbers of sparse features, many of which	page=2 xpos=5 ypos=0 right-column full-justified column-top headchar-lower
I-Body	may be irrelevant. Moreover, the maximum entropy	page=2 xpos=5 ypos=0 right-column full-justified aligned-line headchar-lower
I-Body	and boosting models are known to be well suited to	page=2 xpos=5 ypos=0 right-column full-justified aligned-line headchar-lower
E-Body	handling features that are highly interdependent.	page=2 xpos=5 ypos=0 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	The feature set used consists of position-sensitive,	page=2 xpos=5 ypos=0 right-column left-indent indented-line longer-tail line-space headchar-capital tailchar-comma
I-Body	syntactic, and local collocational features, as de-	page=2 xpos=5 ypos=1 right-column full-justified hanged-line headchar-lower tailchar-hiphen
E-Body	scribed by Yarowsky and Florian (2002).	page=2 xpos=5 ypos=1 right-column right-indent aligned-line shorter-tail year headchar-lower tailchar-period above-blank-line above-double-space above-line-space
B-SubsectionHeader	3.2 Lexical choice mapping model	page=2 xpos=5 ypos=1 right-column right-indent aligned-line shorter-tail line-blank-line line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	Ideally, we would like the WSD model to predict En-	page=2 xpos=5 ypos=2 right-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital tailchar-hiphen
I-Body	glish translations given Chinese target words in con-	page=2 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	text. Such a model requires Chinese training data	page=2 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower
I-Body	annotated with English senses, but such data is not	page=2 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower
I-Body	available. Instead, the WSD system was trained us-	page=2 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ing the Senseval-3 Chinese lexical sample task data.	page=2 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower tailchar-period
I-Body	(This is suboptimal, but reflects the difficulties that	page=2 xpos=5 ypos=3 right-column full-justified aligned-line
I-Body	arise when considering a real translation task; we	page=2 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower
I-Body	cannot assume that sense-annotated data will always	page=2 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower
E-Body	be available for all language pairs.)	page=2 xpos=5 ypos=3 right-column right-indent aligned-line shorter-tail headchar-lower above-line-space
B-Body	The Chinese lexical sample task includes 20 tar-	page=2 xpos=5 ypos=4 right-column left-indent indented-line longer-tail line-space headchar-capital tailchar-hiphen
I-Body	get words. For each word, several senses are defined	page=2 xpos=5 ypos=4 right-column full-justified hanged-line headchar-lower
I-Body	using the HowNet knowledge base. There are an av-	page=2 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	erage of 3.95 senses per target word type, ranging	page=2 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	from 2 to 8. Only about 37 training instances per	page=2 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
E-Body	target word are available.	page=2 xpos=5 ypos=5 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	For the purpose of Chinese to English translation,	page=2 xpos=5 ypos=5 right-column left-indent indented-line longer-tail line-space headchar-capital tailchar-comma
I-Body	the WSD model should predict English translations	page=2 xpos=5 ypos=5 right-column full-justified hanged-line headchar-lower
I-Body	instead of HowNet senses. Fortunately, HowNet	page=2 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	provides English glosses. This allows us to map	page=2 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	each HowNet sense candidate to a set of English	page=2 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	translations, converting the monolingual Chinese	page=2 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	WSD system into a translation lexical choice model.	page=2 xpos=5 ypos=6 right-column full-justified aligned-line headchar-capital tailchar-period
I-Body	We further extended the mapping to include any sig-	page=2 xpos=5 ypos=6 right-column full-justified aligned-line headchar-capital tailchar-hiphen
I-Body	nificant translation choice considered by the SMT	page=2 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
E-Body	system but not in HowNet.	page=2 xpos=5 ypos=7 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-blank-line above-double-space above-line-space
B-SectionHeader	4 The SMT system	page=2 xpos=5 ypos=7 right-column right-indent font-larger aligned-line shorter-tail line-blank-line line-double-space line-space numbered-heading1 above-blank-line above-double-space above-line-space
B-Body	To build a representative baseline statistical machine	page=2 xpos=5 ypos=7 right-column full-justified aligned-line longer-tail line-blank-line line-double-space line-space headchar-capital
I-Body	translation system, we restricted ourselves to mak-	page=2 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ing use of freely available tools, since the potential	page=2 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	contribution of WSD should be easier to see against	page=2 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	this baseline. Note that our focus here is not on the	page=2 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	SMT model itself; our aim is to evaluate the impact	page=2 xpos=5 ypos=8 right-column full-justified aligned-line headchar-capital
I-Body	of WSD on a real Chinese to English statistical ma-	page=2 xpos=5 ypos=9 right-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	chine translation task.	page=2 xpos=5 ypos=9 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period page-bottom
B-Caption	Table 1: Example of the translation candidates before and after mapping for the target word “ 4 ” (lu)	page=3 xpos=0 ypos=0 single-column centered left-indent right-indent font-largest page-top string-table headchar-capital above-double-space above-line-space
Table	__Table 1__	page=3 xpos=-1 ypos=0 single-column left-over right-over box hanged-line longer-tail line-double-space line-space table-area column-bottom above-blank-line above-double-space above-line-space
B-SubsectionHeader	4.1 Alignment model	page=3 xpos=0 ypos=2 left-column right-indent column-top line-blank-line line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	The alignment model was trained with GIZA++	page=3 xpos=0 ypos=2 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	(Och and Ney, 2003), which implements the most	page=3 xpos=0 ypos=3 left-column full-justified aligned-line year
I-Body	typical IBM and HMM alignment models. Transla-	page=3 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tion quality could be improved using more advanced	page=3 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	hybrid phrasal or tree models, but this would inter-	page=3 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	fere with the questions being investigated here. The	page=3 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	alignment model used is IBM-4, as required by our	page=3 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	decoder. The training scheme consists of IBM-1,	page=3 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	HMM, IBM-3 and IBM-4, following (Och and Ney,	page=3 xpos=0 ypos=4 left-column full-justified aligned-line headchar-capital tailchar-comma
E-Body	2003).	page=3 xpos=0 ypos=4 left-column right-indent aligned-line shorter-tail year tailchar-period
B-Body	The training corpus consists of about 1 million	page=3 xpos=0 ypos=4 left-column left-indent indented-line longer-tail headchar-capital
I-Body	sentences from the United Nations Chinese-English	page=3 xpos=0 ypos=5 left-column full-justified hanged-line headchar-lower
I-Body	parallel corpus from LDC. This corpus was automat-	page=3 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ically sentence-aligned, so the training data does not	page=3 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	require as much manual annotation as for the WSD	page=3 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
E-Body	model.	page=3 xpos=0 ypos=5 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-double-space above-line-space
B-SubsectionHeader	4.2 Language model	page=3 xpos=0 ypos=6 left-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	The English language model is a trigram model	page=3 xpos=0 ypos=6 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	trained on the Gigaword newswire data and on the	page=3 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	English side of the UN and Xinhua parallel corpora.	page=3 xpos=0 ypos=6 left-column full-justified aligned-line headchar-capital tailchar-period
I-Body	The language model is also trained using a publicly	page=3 xpos=0 ypos=7 left-column full-justified aligned-line headchar-capital
I-Body	available software, the CMU-Cambridge Statistical	page=3 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	Language Modeling Toolkit (Clarkson and Rosen-	page=3 xpos=0 ypos=7 left-column full-justified aligned-line headchar-capital tailchar-hiphen
E-Body	feld, 1997).	page=3 xpos=0 ypos=7 left-column right-indent aligned-line shorter-tail year headchar-lower tailchar-period above-double-space above-line-space
B-SubsectionHeader	4.3 Decoding	page=3 xpos=0 ypos=7 left-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	The ISI ReWrite decoder (Germann, 2003), which	page=3 xpos=0 ypos=8 left-column full-justified aligned-line longer-tail line-double-space line-space year headchar-capital
I-Body	implements an efficient greedy decoding algorithm,	page=3 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	is used to translate the Chinese sentences, using the	page=3 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	alignment model and language model previously de-	page=3 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	scribed.	page=3 xpos=0 ypos=8 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	Notice that very little contextual information is	page=3 xpos=0 ypos=9 left-column left-indent indented-line longer-tail headchar-capital
I-Body	available to the SMT models. Lexical choice dur-	page=3 xpos=0 ypos=9 left-column full-justified hanged-line headchar-lower tailchar-hiphen above-blank-line above-double-space above-line-space
Page	390	page=3 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
I-Body	ing decoding essentially depends on the translation	page=3 xpos=5 ypos=2 right-column full-justified column-top headchar-lower
I-Body	probabilities learned for the target word, and on the	page=3 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower
E-Body	English language model scores.	page=3 xpos=5 ypos=3 right-column right-indent aligned-line shorter-tail headchar-capital tailchar-period above-double-space above-line-space
B-SectionHeader	5 Experimental method	page=3 xpos=5 ypos=3 right-column right-indent font-larger aligned-line shorter-tail line-double-space line-space numbered-heading1 above-double-space above-line-space
B-SubsectionHeader	5.1 Test set selection	page=3 xpos=5 ypos=3 right-column right-indent aligned-line shorter-tail line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	We extracted the Chinese sentences from the NIST	page=3 xpos=5 ypos=3 right-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	MTEval-04 test set that contain any of the 20 target	page=3 xpos=5 ypos=4 right-column full-justified aligned-line headchar-capital
I-Body	words from the Senseval-3 Chinese lexical sample	page=3 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	target set. For a couple of targets, no instances were	page=3 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	available from the test set. The resulting test set con-	page=3 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tains a total of 175 sentences, which is smaller than	page=3 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	typical MT evaluation test sets, but slightly larger	page=3 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	than the one used for the Senseval Chinese lexical	page=3 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
E-Body	sample task.	page=3 xpos=5 ypos=5 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-double-space above-line-space
B-SubsectionHeader	5.2 Integrating the WSD system predictions	page=3 xpos=5 ypos=5 right-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading2
I-SubsectionHeader	with the SMT model	page=3 xpos=5 ypos=6 right-column left-indent right-indent indented-line shorter-tail headchar-lower above-double-space above-line-space
B-Body	There are numerous possible ways to integrate the	page=3 xpos=5 ypos=6 right-column full-justified hanged-line longer-tail line-double-space line-space headchar-capital
I-Body	WSD system predictions with the SMT model. We	page=3 xpos=5 ypos=6 right-column full-justified aligned-line headchar-capital
I-Body	choose two different straightforward approaches,	page=3 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	which will help analyze the effect of the different	page=3 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	components of the SMT system, as we will see in	page=3 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
E-Body	Section 6.5.	page=3 xpos=5 ypos=7 right-column right-indent aligned-line shorter-tail headchar-capital tailchar-period above-double-space above-line-space
B-SubsubsectionHeader	5.2.1 Using WSD predictions for decoding	page=3 xpos=5 ypos=7 right-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading3 above-line-space
B-Body	In the first approach, we use the WSD sense pre-	page=3 xpos=5 ypos=7 right-column left-indent indented-line longer-tail line-space headchar-capital tailchar-hiphen
I-Body	dictions to constrain the set of English sense candi-	page=3 xpos=5 ypos=8 right-column full-justified hanged-line headchar-lower tailchar-hiphen
I-Body	dates considered by the decoder for each of the tar-	page=3 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	get words. Instead of allowing all the word transla-	page=3 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tion candidates from the translation model, when we	page=3 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	use the WSD predictions we override the translation	page=3 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	model and force the decoder to choose the best trans-	page=3 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	lation from the predefined set of glosses that maps to	page=3 xpos=5 ypos=9 right-column full-justified aligned-line headchar-lower
E-Body	the HowNet sense predicted by the WSD model.	page=3 xpos=5 ypos=9 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period page-bottom
B-Caption	Table 2: Translation quality with and without the WSD model	page=4 xpos=2 ypos=0 single-column centered left-indent right-indent page-top string-table headchar-capital above-line-space
Table	__Table 2__	page=4 xpos=0 ypos=0 single-column centered left-indent right-indent box hanged-line longer-tail line-space table-area column-bottom above-blank-line above-double-space above-line-space
B-SubsubsectionHeader	5.2.2 Using WSD predictions for	page=4 xpos=0 ypos=1 left-column right-indent column-top line-blank-line line-double-space line-space numbered-heading3
I-SubsubsectionHeader	postprocessing	page=4 xpos=0 ypos=1 left-column left-indent right-indent indented-line shorter-tail headchar-lower above-double-space above-line-space
B-Body	In the second approach, we use the WSD predic-	page=4 xpos=0 ypos=2 left-column left-indent hanged-line longer-tail line-double-space line-space headchar-capital tailchar-hiphen
I-Body	tions to postprocess the output of the SMT system:	page=4 xpos=0 ypos=2 left-column full-justified hanged-line headchar-lower tailchar-colon
I-Body	in each output sentence, the translation of the target	page=4 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	word chosen by the SMT model is directly replaced	page=4 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	by the WSD prediction. When the WSD system pre-	page=4 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	dicts more than one candidate, a unique translation	page=4 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	is randomly chosen among them. As discussed later,	page=4 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	this approach can be used to analyze the effect of the	page=4 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
E-Body	language model on the output.	page=4 xpos=0 ypos=3 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	It would also be interesting to use the gold stan-	page=4 xpos=0 ypos=4 left-column left-indent indented-line longer-tail line-space headchar-capital tailchar-hiphen
I-Body	dard or correct sense of the target words instead of	page=4 xpos=0 ypos=4 left-column full-justified hanged-line headchar-lower
I-Body	the WSD model predictions in these experiments.	page=4 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower tailchar-period
I-Body	This would give an upper-bound on performance	page=4 xpos=0 ypos=4 left-column full-justified aligned-line headchar-capital
I-Body	and would quantify the effect of WSD errors. How-	page=4 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ever, we do not have a corpus which contains both	page=4 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	sense annotation and multiple reference translations:	page=4 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower tailchar-colon
I-Body	the MT evaluation corpus is not annotated with the	page=4 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	correct senses of Senseval target words, and the Sen-	page=4 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	seval corpus does not include English translations of	page=4 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
E-Body	the sentences.	page=4 xpos=0 ypos=6 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-blank-line above-double-space above-line-space
B-SectionHeader	6 Results	page=4 xpos=0 ypos=6 left-column right-indent font-larger aligned-line shorter-tail line-blank-line line-double-space line-space numbered-heading1 above-blank-line above-double-space above-line-space
B-SubsectionHeader	6.1 Even state-of-the-art WSD does not help	page=4 xpos=0 ypos=6 left-column right-indent aligned-line longer-tail line-blank-line line-double-space line-space numbered-heading2
I-SubsectionHeader	BLEU score	page=4 xpos=0 ypos=7 left-column left-indent right-indent indented-line shorter-tail headchar-capital above-double-space above-line-space
B-Body	Table 2 summarizes the translation quality scores	page=4 xpos=0 ypos=7 left-column full-justified hanged-line longer-tail line-double-space line-space string-table headchar-capital
I-Body	obtained with and without the WSD model. Using	page=4 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	our WSD model to constrain the translation candi-	page=4 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	dates given to the decoder hurts translation quality,	page=4 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	as measured by the automated BLEU metric (Pap-	page=4 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	ineni et al., 2002).	page=4 xpos=0 ypos=8 left-column right-indent aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Body	Note that we are evaluating on only difficult sen-	page=4 xpos=0 ypos=8 left-column left-indent indented-line longer-tail line-space headchar-capital tailchar-hiphen
I-Body	tences containing the problematic target words from	page=4 xpos=0 ypos=8 left-column full-justified hanged-line headchar-lower
I-Body	the lexical sample task, so BLEU scores can be ex-	page=4 xpos=0 ypos=9 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	pected to be on the low side.	page=4 xpos=0 ypos=9 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-blank-line above-double-space above-line-space
Page	391	page=4 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
B-SubsectionHeader	6.2 WSD still does not help BLEU score with	page=4 xpos=5 ypos=1 right-column right-indent column-top numbered-heading2
I-SubsectionHeader	improved translation candidates	page=4 xpos=5 ypos=1 right-column left-indent right-indent indented-line shorter-tail headchar-lower above-double-space above-line-space
B-Body	One could argue that the translation candidates cho-	page=4 xpos=5 ypos=2 right-column full-justified hanged-line longer-tail line-double-space line-space headchar-capital tailchar-hiphen
I-Body	sen by the WSD models do not help because they	page=4 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower
I-Body	are only glosses obtained from the HowNet dictio-	page=4 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	nary. They consist of the root form of words only,	page=4 xpos=5 ypos=2 right-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	while the SMT model can learn many more transla-	page=4 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tions for each target word, including inflected forms	page=4 xpos=5 ypos=3 right-column full-justified aligned-line headchar-lower
E-Body	and synonyms.	page=4 xpos=5 ypos=3 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	In order to avoid artificially penalizing the WSD	page=4 xpos=5 ypos=3 right-column left-indent indented-line longer-tail line-space headchar-capital
I-Body	system by limiting its translation candidates to the	page=4 xpos=5 ypos=3 right-column full-justified hanged-line headchar-lower
I-Body	HowNet glosses, we expand the translation set us-	page=4 xpos=5 ypos=4 right-column full-justified aligned-line headchar-capital tailchar-hiphen
I-Body	ing the bilexicon learned during translation model	page=4 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	training. For each target word, we consider the En-	page=4 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	glish words that are given a high translation prob-	page=4 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ability, and manually map each of these English	page=4 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	words to the sense categories defined for the Sen-	page=4 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	seval model. At decoding time, the set of transla-	page=4 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tion candidates considered by the language model is	page=4 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	therefore larger, and closer to that considered by the	page=4 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
E-Body	pure SMT system.	page=4 xpos=5 ypos=5 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	The results in Table 2 show that the improved	page=4 xpos=5 ypos=6 right-column left-indent indented-line longer-tail line-space headchar-capital
I-Body	translation candidates do not help BLEU score. The	page=4 xpos=5 ypos=6 right-column full-justified hanged-line headchar-lower
I-Body	translation quality obtained with SMT alone is still	page=4 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	better than when the improved WSD Model is used.	page=4 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower tailchar-period
I-Body	The simpler approach of using WSD predictions in	page=4 xpos=5 ypos=6 right-column full-justified aligned-line headchar-capital
I-Body	postprocessing yields better BLEU score than the	page=4 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
I-Body	decoding approach, but still does not outperform the	page=4 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
E-Body	SMT model.	page=4 xpos=5 ypos=7 right-column right-indent aligned-line shorter-tail headchar-capital tailchar-period above-double-space above-line-space
B-SubsectionHeader	6.3 WSD helps translation quality for very few	page=4 xpos=5 ypos=7 right-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading2
I-SubsectionHeader	target words	page=4 xpos=5 ypos=8 right-column left-indent right-indent indented-line shorter-tail headchar-lower above-double-space above-line-space
B-Body	If we break down the test set and evaluate the effect	page=4 xpos=5 ypos=8 right-column full-justified hanged-line longer-tail line-double-space line-space headchar-capital
I-Body	of the WSD per target word, we find that for all but	page=4 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	two of the target words WSD either hurts the BLEU	page=4 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	score or does not help it, which shows that the de-	page=4 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	crease in BLEU is not only due to a few isolated tar-	page=4 xpos=5 ypos=9 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	get words for which the Senseval sense distinctions	page=4 xpos=5 ypos=9 right-column full-justified aligned-line headchar-lower page-bottom
E-Body	are not helpful.	page=5 xpos=0 ypos=0 left-column right-indent page-top headchar-lower tailchar-period above-double-space above-line-space
B-SubsectionHeader	6.4 The “language model effect”	page=5 xpos=0 ypos=0 left-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	Error analysis revealed some surprising effects. One	page=5 xpos=0 ypos=0 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	particularly dismaying effect is that even in cases	page=5 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower
I-Body	where the WSD model is able to predict a better tar-	page=5 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	get word translation than the SMT model, to use the	page=5 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower
I-Body	better target word translation surprisingly often still	page=5 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower
E-Body	leads to a lower BLEU score.	page=5 xpos=0 ypos=1 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	The phrasal coherence property can help explain	page=5 xpos=0 ypos=1 left-column left-indent indented-line longer-tail headchar-capital
I-Body	this surprising effect we observed. The translation	page=5 xpos=0 ypos=1 left-column full-justified hanged-line headchar-lower
I-Body	chosen by the SMT model will tend to be more likely	page=5 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	than the WSD prediction according to the language	page=5 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	model; otherwise, it would also have been predicted	page=5 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	by SMT. The translation with the higher language	page=5 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	model probability influences the translation of its	page=5 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	neighbors, thus potentially improving BLEU score,	page=5 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	while the WSD prediction may not have been seen	page=5 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	occurring within phrases often enough, thereby low-	page=5 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	ering BLEU score.	page=5 xpos=0 ypos=3 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	For example, we observe that the WSD model	page=5 xpos=0 ypos=3 left-column left-indent indented-line longer-tail headchar-capital
I-Body	translation for “ àâ ” (chongji), where the SMT	page=5 xpos=0 ypos=4 left-column full-justified font-largest hanged-line headchar-lower
I-Body	sometimes correctly predicts “impact” as a better	page=5 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower above-blank-line above-double-space above-line-space
I-Body	model selects “shock”. In these cases, some of	page=5 xpos=0 ypos=4 left-column full-justified aligned-line line-blank-line line-double-space line-space headchar-lower
I-Body	the reference translations also use “impact”. How-	page=5 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ever, even when the WSD model constrains the de-	page=5 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	coder to select “impact” rather than “shock”, the	page=5 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	resulting sentence translation yields a lower BLEU	page=5 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	score. This happens because the SMT model does	page=5 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	not know how to use “impact” correctly (if it did, it	page=5 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	would likely have chosen “impact” itself). Forcing	page=5 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
I-Body	the lexical choice “impact” simply causes the SMT	page=5 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	model to generate phrases such as “against Japan for	page=5 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	peace constitution impact” instead of “against Japan	page=5 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
I-Body	for peace constitution shocks”. This actually lowers	page=5 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
E-Body	BLEU score, because of the n-gram effects.	page=5 xpos=0 ypos=6 left-column right-indent aligned-line shorter-tail headchar-capital tailchar-period above-double-space above-line-space
B-SubsectionHeader	6.5 Using WSD predictions in postprocessing	page=5 xpos=0 ypos=7 left-column right-indent aligned-line longer-tail line-double-space line-space numbered-heading2
I-SubsectionHeader	does not help BLEU score either	page=5 xpos=0 ypos=7 left-column left-indent right-indent indented-line shorter-tail headchar-lower above-double-space above-line-space
B-Body	In the postprocessing approach, decoding is done	page=5 xpos=0 ypos=7 left-column full-justified hanged-line longer-tail line-double-space line-space headchar-capital
I-Body	before knowing the WSD predictions, which elim-	page=5 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	inates the “language model effect”. Even in these	page=5 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	conditions, the SMT model alone is still the best per-	page=5 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	forming system.	page=5 xpos=0 ypos=8 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period
B-Body	The postprocessing approach also outperforms	page=5 xpos=0 ypos=8 left-column left-indent indented-line longer-tail headchar-capital
I-Body	the integrated decoding approach, which shows that	page=5 xpos=0 ypos=8 left-column full-justified hanged-line headchar-lower
I-Body	the language model is not able to make use of the	page=5 xpos=0 ypos=9 left-column full-justified aligned-line headchar-lower
I-Body	WSD predictions. One could expect that letting the	page=5 xpos=0 ypos=9 left-column full-justified aligned-line headchar-capital above-blank-line above-double-space above-line-space
Page	392	page=5 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
B-Caption	Table 3: BLEU scores per target word: WSD helps	page=5 xpos=5 ypos=0 right-column full-justified column-top string-table headchar-capital
E-Caption	for very few target words	page=5 xpos=5 ypos=0 right-column right-indent aligned-line shorter-tail headchar-lower above-line-space
Table	__Table 3__	page=5 xpos=5 ypos=0 right-column centered left-indent right-indent box longer-tail line-space table-area above-blank-line above-double-space above-line-space
I-Body	decoder choose among the WSD translations also	page=5 xpos=5 ypos=4 right-column full-justified line-blank-line line-double-space line-space headchar-lower
I-Body	yields a better translation of the context. This is	page=5 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower
I-Body	indeed the case, but for very few examples only:	page=5 xpos=5 ypos=4 right-column full-justified aligned-line headchar-lower tailchar-colon
I-Body	for instance the target word “ 0 ” (difang) is bet-	page=5 xpos=5 ypos=4 right-column full-justified font-largest aligned-line headchar-lower tailchar-hiphen
I-Body	ter used in the integrated decoding ouput “the place	page=5 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	of local employment” , than in the postprocessing	page=5 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	output “the place employment situation”. Instead,	page=5 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower tailchar-comma
I-Body	the majority of cases follow the pattern illustrated	page=5 xpos=5 ypos=5 right-column full-justified aligned-line headchar-lower
I-Body	“  ” (lao): the SMT system produces the best output	page=5 xpos=5 ypos=6 right-column full-justified font-largest aligned-line
I-Body	by the following example where the target word is	page=5 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower above-blank-line above-double-space above-line-space
I-Body	(“the newly elected President will still face old prob-	page=5 xpos=5 ypos=6 right-column full-justified aligned-line line-blank-line line-double-space line-space tailchar-hiphen
I-Body	lems”), the postprocessed output uses the fluent sen-	page=5 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tence with a different translation (“the newly elected	page=5 xpos=5 ypos=6 right-column full-justified aligned-line headchar-lower
I-Body	President will still face outdated problems”), while	page=5 xpos=5 ypos=7 right-column full-justified aligned-line headchar-capital
I-Body	the translation is not used correctly with the decod-	page=5 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ing approach (“the newly elected President will face	page=5 xpos=5 ypos=7 right-column full-justified aligned-line headchar-lower
E-Body	problems still to be outdated”).	page=5 xpos=5 ypos=7 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-blank-line above-double-space above-line-space
B-SubsectionHeader	6.6 BLEU score bias	page=5 xpos=5 ypos=8 right-column right-indent aligned-line shorter-tail line-blank-line line-double-space line-space numbered-heading2 above-double-space above-line-space
B-Body	The “language model effect” highlights one of the	page=5 xpos=5 ypos=8 right-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	potential weaknesses of the BLEU score. BLEU pe-	page=5 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	nalizes for phrasal incoherence, which in the present	page=5 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower
I-Body	study means that it can sometimes sacrifice ade-	page=5 xpos=5 ypos=8 right-column full-justified aligned-line headchar-lower tailchar-hiphen
E-Body	quacy for fluency.	page=5 xpos=5 ypos=9 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	However, the characteristics of BLEU are by	page=5 xpos=5 ypos=9 right-column left-indent indented-line longer-tail line-space headchar-capital page-bottom
I-Body	no means solely responsible for the problems with	page=6 xpos=0 ypos=0 left-column full-justified page-top headchar-lower
I-Body	WSD that we observed. To doublecheck that n-gram	page=6 xpos=0 ypos=0 left-column full-justified aligned-line headchar-capital
I-Body	effects were not unduly impacting our study, we also	page=6 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower
I-Body	evaluated using BLEU-1, which gave largely simi-	page=6 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	lar results as the standard BLEU-4 scores reported	page=6 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower
E-Body	above.	page=6 xpos=0 ypos=0 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-double-space above-line-space
B-SectionHeader	7 Related work	page=6 xpos=0 ypos=1 left-column right-indent font-larger aligned-line longer-tail line-double-space line-space numbered-heading1 above-double-space above-line-space
B-Body	Most translation disambiguation tasks are defined	page=6 xpos=0 ypos=1 left-column full-justified aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	similarly to the Senseval Multilingual lexical sam-	page=6 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ple tasks. In Senseval-3, the English to Hindi trans-	page=6 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	lation disambigation task was defined identically to	page=6 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	the English lexical sample task, except that the WSD	page=6 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	models are expected to predict Hindi translations in-	page=6 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	stead of WordNet senses. This differs from our ap-	page=6 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	proach which consists of producing the translation	page=6 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	of complete sentences, and not only of a predefined	page=6 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
E-Body	set of target words.	page=6 xpos=0 ypos=3 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	Brown et al. (1991) proposed a WSD algorithm to	page=6 xpos=0 ypos=3 left-column left-indent indented-line longer-tail line-space year headchar-capital
I-Body	disambiguate English translations of French target	page=6 xpos=0 ypos=3 left-column full-justified hanged-line headchar-lower
I-Body	words based on the single most informative context	page=6 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	feature. In a pilot study, they found that using this	page=6 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	WSD method in their French-English SMT system	page=6 xpos=0 ypos=4 left-column full-justified aligned-line headchar-capital
I-Body	helped translation quality, manually evaluated using	page=6 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	the number of acceptable translations. However, this	page=6 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
I-Body	study is limited to the unrealistic case of words that	page=6 xpos=0 ypos=5 left-column full-justified aligned-line headchar-lower
E-Body	have exactly two senses in the other language.	page=6 xpos=0 ypos=5 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	Most previous work has focused on the distinct	page=6 xpos=0 ypos=5 left-column left-indent indented-line longer-tail line-space headchar-capital
I-Body	problem of exploiting various bilingual resources	page=6 xpos=0 ypos=5 left-column full-justified hanged-line headchar-lower
I-Body	(e.g., parallel or comparable corpora, or even MT	page=6 xpos=0 ypos=5 left-column full-justified aligned-line
I-Body	systems) to help WSD. The goal is to achieve accu-	page=6 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	rate WSD with minimum amounts of annotated data.	page=6 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower tailchar-period
I-Body	Again, this differs from our objective which consists	page=6 xpos=0 ypos=6 left-column full-justified aligned-line headchar-capital
I-Body	of using WSD to improve performance on a full ma-	page=6 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	chine translation task, and is measured in terms of	page=6 xpos=0 ypos=6 left-column full-justified aligned-line headchar-lower
E-Body	translation quality.	page=6 xpos=0 ypos=7 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	For instance, Ng et al. (2003) showed that it is	page=6 xpos=0 ypos=7 left-column left-indent indented-line longer-tail line-space year headchar-capital
I-Body	possible to use word aligned parallel corpora to train	page=6 xpos=0 ypos=7 left-column full-justified hanged-line headchar-lower
I-Body	accurate supervised WSD models. The objective is	page=6 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	different; it is not possible for us to use this method	page=6 xpos=0 ypos=7 left-column full-justified aligned-line headchar-lower
I-Body	to train our WSD model without undermining the	page=6 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	question we aim to investigate: we would need to	page=6 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	use the SMT model to word-align the parallel sen-	page=6 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tences, which could too strongly bias the predic-	page=6 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tions of the WSD model towards those of the SMT	page=6 xpos=0 ypos=8 left-column full-justified aligned-line headchar-lower
I-Body	model, instead of combining predictive information	page=6 xpos=0 ypos=9 left-column full-justified aligned-line headchar-lower
E-Body	from independent sources as we aim to study here.	page=6 xpos=0 ypos=9 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-blank-line above-double-space above-line-space
Page	393	page=6 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
B-Body	Other work includes Li and Li (2002) who pro-	page=6 xpos=5 ypos=0 right-column left-indent right-over column-top year headchar-capital tailchar-hiphen
I-Body	pose a bilingual bootstrapping method to learn a	page=6 xpos=5 ypos=0 right-column right-over hanged-line headchar-lower
I-Body	translation disambiguation WSD model, and Diab	page=6 xpos=5 ypos=0 right-column right-over aligned-line headchar-lower
I-Body	(2004) who exploited large amounts of automati-	page=6 xpos=5 ypos=0 right-column right-over aligned-line year tailchar-hiphen
I-Body	cally generated noisy parallel data to learn WSD	page=6 xpos=5 ypos=0 right-column right-over aligned-line headchar-lower
E-Body	models in an unsupervised bootstrapping scheme.	page=6 xpos=5 ypos=0 right-column right-over aligned-line shorter-tail headchar-lower tailchar-period above-double-space above-line-space
B-SectionHeader	8 Conclusion	page=6 xpos=5 ypos=1 right-column right-indent font-larger aligned-line shorter-tail line-double-space line-space numbered-heading1 above-double-space above-line-space
B-Body	The empirical study presented here argues that we	page=6 xpos=5 ypos=1 right-column right-over aligned-line longer-tail line-double-space line-space headchar-capital
I-Body	can expect that it will be quite difficult, at the least,	page=6 xpos=5 ypos=1 right-column right-over aligned-line headchar-lower tailchar-comma
I-Body	to use standard WSD models to obtain significant	page=6 xpos=5 ypos=2 right-column right-over aligned-line headchar-lower
I-Body	improvements to statistical MT systems, even when	page=6 xpos=5 ypos=2 right-column right-over aligned-line headchar-lower
I-Body	supervised WSD models are used. This casts signif-	page=6 xpos=5 ypos=2 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	icant doubt on a commonly-held, but unproven, as-	page=6 xpos=5 ypos=2 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	sumption to the contrary. We have presented empiri-	page=6 xpos=5 ypos=2 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	cally based analysis of the reasons for this surprising	page=6 xpos=5 ypos=3 right-column right-over aligned-line headchar-lower
E-Body	finding.	page=6 xpos=5 ypos=3 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	We have seen that one major factor is that the	page=6 xpos=5 ypos=3 right-column left-indent right-over indented-line longer-tail line-space headchar-capital
I-Body	statistical MT model is sufficiently accurate so that	page=6 xpos=5 ypos=3 right-column right-over hanged-line headchar-lower
I-Body	within the training domain, even the state-of-the-art	page=6 xpos=5 ypos=3 right-column right-over aligned-line headchar-lower
I-Body	dedicated WSD model is only able to improve on its	page=6 xpos=5 ypos=4 right-column right-over aligned-line headchar-lower
I-Body	lexical choice predictions in a relatively small pro-	page=6 xpos=5 ypos=4 right-column right-over aligned-line headchar-lower tailchar-hiphen
E-Body	portion of cases.	page=6 xpos=5 ypos=4 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Body	A second major factor is that even when the ded-	page=6 xpos=5 ypos=4 right-column left-indent right-over indented-line longer-tail line-space headchar-capital tailchar-hiphen
I-Body	icated WSD model makes better predictions, cur-	page=6 xpos=5 ypos=4 right-column right-over hanged-line headchar-lower tailchar-hiphen
I-Body	rent statistical MT models are unable to exploit this.	page=6 xpos=5 ypos=5 right-column right-over aligned-line headchar-lower tailchar-period
I-Body	Under this interpretation of our results, the depen-	page=6 xpos=5 ypos=5 right-column right-over aligned-line headchar-capital tailchar-hiphen
I-Body	dence on the language model in current SMT ar-	page=6 xpos=5 ypos=5 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	chitectures is excessive. One could of course ar-	page=6 xpos=5 ypos=5 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	gue that drastically increasing the amount of train-	page=6 xpos=5 ypos=5 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	ing data for the language model might overcome the	page=6 xpos=5 ypos=6 right-column right-over aligned-line headchar-lower
I-Body	problems from the language model effect. Given	page=6 xpos=5 ypos=6 right-column right-over aligned-line headchar-lower
I-Body	combinatorial problems, however, there is no way at	page=6 xpos=5 ypos=6 right-column right-over aligned-line headchar-lower
I-Body	present of telling whether the amount of data needed	page=6 xpos=5 ypos=6 right-column right-over aligned-line headchar-lower
I-Body	to achieve this is realistic, particularly for translation	page=6 xpos=5 ypos=6 right-column right-over aligned-line headchar-lower
I-Body	across many different domains. On the other hand, if	page=6 xpos=5 ypos=7 right-column right-over aligned-line headchar-lower
I-Body	the SMT architecture cannot make use of WSD pre-	page=6 xpos=5 ypos=7 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	dictions, even when they are in fact better than the	page=6 xpos=5 ypos=7 right-column right-over aligned-line headchar-lower
I-Body	SMT’s lexical choices, then perhaps some alterna-	page=6 xpos=5 ypos=7 right-column right-over aligned-line headchar-capital tailchar-hiphen
I-Body	tive model striking a different balance of adequacy	page=6 xpos=5 ypos=7 right-column right-over aligned-line headchar-lower
I-Body	and fluency is called for. Ultimately, after all, WSD	page=6 xpos=5 ypos=8 right-column right-over aligned-line headchar-lower
I-Body	is a method of compensating for sparse data. Thus	page=6 xpos=5 ypos=8 right-column right-over aligned-line headchar-lower
I-Body	it may be that the present inability of WSD models	page=6 xpos=5 ypos=8 right-column right-over aligned-line headchar-lower
I-Body	to help improve accuracy of SMT systems stems not	page=6 xpos=5 ypos=8 right-column right-over aligned-line headchar-lower
I-Body	from an inherent weakness of dedicated WSD mod-	page=6 xpos=5 ypos=8 right-column right-over aligned-line headchar-lower tailchar-hiphen
I-Body	els, but rather from limitations of present-day SMT	page=6 xpos=5 ypos=9 right-column right-over aligned-line headchar-lower
E-Body	architectures.	page=6 xpos=5 ypos=9 right-column right-indent aligned-line shorter-tail headchar-lower tailchar-period page-bottom
B-Body	To further test this, our experiments could be	page=7 xpos=0 ypos=0 left-column left-indent page-top headchar-capital
I-Body	tried on other statistical MT models. For exam-	page=7 xpos=0 ypos=0 left-column full-justified hanged-line headchar-lower tailchar-hiphen
I-Body	ple, the WSD model’s predictions could be em-	page=7 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ployed in a Bracketing ITG translation model such	page=7 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower
I-Body	as Wu (1996) or Zens et al. (2004), or alternatively	page=7 xpos=0 ypos=0 left-column full-justified aligned-line year headchar-lower
I-Body	they could be incorporated as features for rerank-	page=7 xpos=0 ypos=0 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ing in a maximum-entropy SMT model (Och and	page=7 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower
I-Body	Ney, 2002), instead of using them to constrain the	page=7 xpos=0 ypos=1 left-column full-justified aligned-line year headchar-capital
I-Body	sentence translation hypotheses as done here. How-	page=7 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ever, the preceding discussion argues that it is doubt-	page=7 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	ful that this would produce significantly different re-	page=7 xpos=0 ypos=1 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	sults, since the inherent problem from the “language	page=7 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	model effect” would largely remain, causing sen-	page=7 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	tence translations that include the WSD’s preferred	page=7 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	lexical choices to be discounted. For similar rea-	page=7 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	sons, we suspect our findings may also hold even for	page=7 xpos=0 ypos=2 left-column full-justified aligned-line headchar-lower
I-Body	more sophisticated statistical MT models that rely	page=7 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	heavily on n-gram language models. A more gram-	page=7 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	matically structured statistical MT model that less n-	page=7 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower tailchar-hiphen
I-Body	gram oriented, such as the ITG based “grammatical	page=7 xpos=0 ypos=3 left-column full-justified aligned-line headchar-lower
I-Body	channel” translation model (Wu and Wong, 1998),	page=7 xpos=0 ypos=3 left-column full-justified aligned-line year headchar-lower tailchar-comma
I-Body	might make more effective use of the WSD model’s	page=7 xpos=0 ypos=4 left-column full-justified aligned-line headchar-lower
E-Body	predictions.	page=7 xpos=0 ypos=4 left-column right-indent aligned-line shorter-tail headchar-lower tailchar-period above-double-space above-line-space
ReferenceHeader	References	page=7 xpos=0 ypos=4 left-column right-indent font-larger aligned-line longer-tail line-double-space line-space string-reference headchar-capital above-double-space above-line-space
B-Reference	Peter Brown, Stephen Della Pietra, Vincent Della Pietra, and	page=7 xpos=0 ypos=5 left-column full-justified font-smallest aligned-line longer-tail line-double-space line-space headchar-capital
I-Reference	Robert Mercer. Word-sense disambiguation using statistical	page=7 xpos=0 ypos=5 left-column left-indent font-smallest indented-line headchar-capital
I-Reference	methods. In Proceedings of 29th meeting of the Associa-	page=7 xpos=0 ypos=5 left-column left-indent font-smallest aligned-line headchar-lower tailchar-hiphen
I-Reference	tion for Computational Linguistics, pages 264–270, Berke-	page=7 xpos=0 ypos=5 left-column left-indent font-smallest aligned-line headchar-lower tailchar-hiphen
I-Reference	ley, California, 1991.	page=7 xpos=0 ypos=5 left-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	Marine Carpuat, Weifeng Su, and Dekai Wu. Augmenting en-	page=7 xpos=0 ypos=5 left-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital tailchar-hiphen
I-Reference	semble classification for word sense disambiguation with a	page=7 xpos=0 ypos=5 left-column left-indent font-smallest indented-line headchar-lower
I-Reference	Kernel PCA model. In Proceedings of Senseval-3, Third	page=7 xpos=0 ypos=6 left-column left-indent font-smallest aligned-line headchar-capital
I-Reference	International Workshop on Evaluating Word Sense Disam-	page=7 xpos=0 ypos=6 left-column left-indent font-smallest aligned-line headchar-capital tailchar-hiphen
I-Reference	biguation Systems, Barcelona, July 2004. SIGLEX, Associ-	page=7 xpos=0 ypos=6 left-column left-indent font-smallest aligned-line year headchar-lower tailchar-hiphen
I-Reference	ation for Computational Linguistics.	page=7 xpos=0 ypos=6 left-column left-indent right-indent font-smallest aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Reference	Xavier Carreras, Lluı́s Màrques, and Lluı́s Padró. Named en-	page=7 xpos=0 ypos=6 left-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital tailchar-hiphen
I-Reference	tity extraction using AdaBoost. In Dan Roth and Antal van	page=7 xpos=0 ypos=6 left-column left-indent font-smallest indented-line headchar-lower
I-Reference	den Bosch, editors, Proceedings of CoNLL-2002, pages 167–	page=7 xpos=0 ypos=7 left-column left-indent font-smallest aligned-line year headchar-lower
I-Reference	170, Taipei, Taiwan, 2002.	page=7 xpos=0 ypos=7 left-column left-indent right-indent font-smallest aligned-line shorter-tail year tailchar-period above-line-space
B-Reference	Philip Clarkson and Ronald Rosenfeld. Statistical language	page=7 xpos=0 ypos=7 left-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	modeling using the CMU-Cambridge toolkit. In Proceed-	page=7 xpos=0 ypos=7 left-column left-indent font-smallest indented-line headchar-lower tailchar-hiphen
I-Reference	ings of Eurospeech ’97, pages 2707–2710, Rhodes, Greece,	page=7 xpos=0 ypos=7 left-column left-indent font-smallest aligned-line headchar-lower tailchar-comma
I-Reference	1997.	page=7 xpos=0 ypos=7 left-column left-indent right-indent font-smallest aligned-line shorter-tail year tailchar-period above-line-space
B-Reference	Mona Diab. Relieving the data acquisition bottleneck in word	page=7 xpos=0 ypos=8 left-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	sense disambiguation. In Proceedings of the 42nd Annual	page=7 xpos=0 ypos=8 left-column left-indent font-smallest indented-line headchar-lower
I-Reference	Meeting of the Association for Computational Linguistics,	page=7 xpos=0 ypos=8 left-column left-indent font-smallest aligned-line headchar-capital tailchar-comma
I-Reference	2004.	page=7 xpos=0 ypos=8 left-column left-indent right-indent font-smallest aligned-line shorter-tail year tailchar-period above-line-space
B-Reference	Yoram Freund and Robert E. Schapire. A decision-theoretic	page=7 xpos=0 ypos=8 left-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	generalization of on-line learning and an application to	page=7 xpos=0 ypos=8 left-column left-indent font-smallest indented-line headchar-lower
I-Reference	boosting. In Journal of Computer and System Sciences,	page=7 xpos=0 ypos=9 left-column left-indent font-smallest aligned-line headchar-lower tailchar-comma
I-Reference	55(1), pages 119–139, 1997.	page=7 xpos=0 ypos=9 left-column left-indent right-indent font-smallest aligned-line shorter-tail year tailchar-period above-line-space
B-Reference	Ulrich Germann. Greeedy decoding for statistical machine	page=7 xpos=0 ypos=9 left-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital above-blank-line above-double-space above-line-space
Page	394	page=7 xpos=4 ypos=9 left-column left-indent right-over indented-line longer-tail line-blank-line line-double-space line-space numeric-only column-bottom
I-Reference	translation in almost linear time. In Proceedings of HLT-	page=7 xpos=5 ypos=0 right-column left-indent font-smallest column-top headchar-lower tailchar-hiphen
I-Reference	NAACL-2003. Edmonton, AB, Canada, 2003.	page=7 xpos=5 ypos=0 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-capital tailchar-period above-line-space
B-Reference	E.T. Jaynes. Where do we Stand on Maximum Entropy? MIT	page=7 xpos=5 ypos=0 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	Press, Cambridge MA, 1978.	page=7 xpos=5 ypos=0 right-column left-indent right-indent font-smallest indented-line shorter-tail year headchar-capital tailchar-period above-line-space
B-Reference	Dan Klein and Christopher D. Manning. Conditional structure	page=7 xpos=5 ypos=0 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	versus conditional estimation in NLP models. In Proceed-	page=7 xpos=5 ypos=0 right-column left-indent font-smallest indented-line headchar-lower tailchar-hiphen
I-Reference	ings of EMNLP-2002, Conference on Empirical Methods	page=7 xpos=5 ypos=1 right-column left-indent font-smallest aligned-line year headchar-lower
I-Reference	in Natural Language Processing, pages 9–16, Philadelphia,	page=7 xpos=5 ypos=1 right-column left-indent font-smallest aligned-line headchar-lower tailchar-comma
I-Reference	July 2002. SIGDAT, Association for Computational Linguis-	page=7 xpos=5 ypos=1 right-column left-indent font-smallest aligned-line year headchar-capital tailchar-hiphen
I-Reference	tics.	page=7 xpos=5 ypos=1 right-column left-indent right-indent font-smallest aligned-line shorter-tail headchar-lower tailchar-period above-line-space
B-Reference	Cong Li and Hang Li. Word translation disambiguation using	page=7 xpos=5 ypos=1 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	bilingual bootstrapping. In Proceedings of the 40th Annual	page=7 xpos=5 ypos=1 right-column left-indent font-smallest indented-line headchar-lower
I-Reference	Meeting of the Association for Computational Linguistics,	page=7 xpos=5 ypos=1 right-column left-indent font-smallest aligned-line headchar-capital tailchar-comma
I-Reference	pages 343–351, 2002.	page=7 xpos=5 ypos=2 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	Hwee Tou Ng, Bin Wang, and Yee Seng Chan. Exploiting paral-	page=7 xpos=5 ypos=2 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital tailchar-hiphen
I-Reference	lel texts for word sense disambiguation: An empirical study.	page=7 xpos=5 ypos=2 right-column left-indent font-smallest indented-line headchar-lower tailchar-period
I-Reference	In Proceedings of ACL-03, Sapporo, Japan, pages 455–462,	page=7 xpos=5 ypos=2 right-column left-indent font-smallest aligned-line headchar-capital tailchar-comma
I-Reference	2003.	page=7 xpos=5 ypos=2 right-column left-indent right-indent font-smallest aligned-line shorter-tail year tailchar-period above-line-space
B-Reference	Franz Och and Hermann Ney. Discriminative training and max-	page=7 xpos=5 ypos=2 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital tailchar-hiphen
I-Reference	imum entropy models for statistical machine translation. In	page=7 xpos=5 ypos=3 right-column left-indent font-smallest indented-line headchar-lower
I-Reference	Proceedings of ACL-02, Philadelphia, 2002.	page=7 xpos=5 ypos=3 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-capital tailchar-period above-line-space
B-Reference	Franz Josef Och and Hermann Ney. A systematic comparison	page=7 xpos=5 ypos=3 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	of various statistical alignment models. Computational Lin-	page=7 xpos=5 ypos=3 right-column left-indent font-smallest indented-line headchar-lower tailchar-hiphen
I-Reference	guistics, 29(1):19–52, 2003.	page=7 xpos=5 ypos=3 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing	page=7 xpos=5 ypos=3 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	Zhu. BLEU: a method for automatic evaluation of machine	page=7 xpos=5 ypos=4 right-column left-indent font-smallest indented-line headchar-capital
I-Reference	translation. In Proceedings of the 40th Annual Meeting of	page=7 xpos=5 ypos=4 right-column left-indent font-smallest aligned-line headchar-lower
I-Reference	the Association for Computational Linguistics, 2002.	page=7 xpos=5 ypos=4 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	Robert E. Schapire and Yoram Singer. BoosTexter: A boosting-	page=7 xpos=5 ypos=4 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital tailchar-hiphen
I-Reference	based system for text categorization. Machine Learning,	page=7 xpos=5 ypos=4 right-column left-indent font-smallest indented-line headchar-lower tailchar-comma
I-Reference	39(2):135–168, 2000.	page=7 xpos=5 ypos=4 right-column left-indent right-indent font-smallest aligned-line shorter-tail year tailchar-period above-line-space
B-Reference	Bernhard Schölkopf, Alexander Smola, and Klaus-Rober	page=7 xpos=5 ypos=5 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	Müller. Nonlinear component analysis as a kernel eigenvalue	page=7 xpos=5 ypos=5 right-column left-indent font-smallest indented-line headchar-capital
I-Reference	problem. Neural Computation, 10(5), 1998.	page=7 xpos=5 ypos=5 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	Dekai Wu and Hongsing Wong. Machine translation with a	page=7 xpos=5 ypos=5 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	stochastic grammatical channel. In Proceedings of COLING-	page=7 xpos=5 ypos=5 right-column left-indent font-smallest indented-line headchar-lower tailchar-hiphen
I-Reference	ACL’98, Montreal,Canada, August 1998.	page=7 xpos=5 ypos=5 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-capital tailchar-period above-line-space
B-Reference	Dekai Wu, Weifeng Su, and Marine Carpuat. A Kernel PCA	page=7 xpos=5 ypos=6 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	method for superior word sense disambiguation. In Proceed-	page=7 xpos=5 ypos=6 right-column left-indent font-smallest indented-line headchar-lower tailchar-hiphen
I-Reference	ings of the 42nd Annual Meeting of the Association for Com-	page=7 xpos=5 ypos=6 right-column left-indent font-smallest aligned-line headchar-lower tailchar-hiphen
I-Reference	putational Linguistics, Barcelona, July 2004.	page=7 xpos=5 ypos=6 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	Dekai Wu. A polynomial-time algorithm for statistical machine	page=7 xpos=5 ypos=6 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	translation. In Proceedings of 34th Annual Meeting of the	page=7 xpos=5 ypos=6 right-column left-indent font-smallest indented-line headchar-lower
I-Reference	Association for Computational Linguistics, Santa Cruz, Cal-	page=7 xpos=5 ypos=7 right-column left-indent font-smallest aligned-line headchar-capital tailchar-hiphen
I-Reference	ifornia, June 1996.	page=7 xpos=5 ypos=7 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	David Yarowsky and Radu Florian. Evaluating sense disam-	page=7 xpos=5 ypos=7 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital tailchar-hiphen
I-Reference	biguation across diverse parameter spaces. Natural Lan-	page=7 xpos=5 ypos=7 right-column left-indent font-smallest indented-line headchar-lower tailchar-hiphen
I-Reference	guage Engineering, 8(4):293–310, 2002.	page=7 xpos=5 ypos=7 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-lower tailchar-period above-line-space
B-Reference	Richard Zens, Hermann Ney, Taro Watanabe, and Eiichiro	page=7 xpos=5 ypos=7 right-column full-justified font-smallest hanged-line longer-tail line-space headchar-capital
I-Reference	Sumita. Reordering constraints for phrase-based statisti-	page=7 xpos=5 ypos=8 right-column left-indent font-smallest indented-line headchar-capital tailchar-hiphen
I-Reference	cal machine translation. In Proceedings of COLING-2004,	page=7 xpos=5 ypos=8 right-column left-indent font-smallest aligned-line year headchar-lower tailchar-comma
I-Reference	Geneva,Switzerland, August 2004.	page=7 xpos=5 ypos=8 right-column left-indent right-indent font-smallest aligned-line shorter-tail year headchar-capital tailchar-period
